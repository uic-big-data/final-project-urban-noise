\section{Introduction}
Noise Pollution is a grievous problem which needs to be tackled, as it’s a growing concern for many urban residents. Sounds that are not particularly loud but are nonetheless undesirable and uncontrollable can have serious implications for the listener, particularly if they occur over a long period of time ~\cite{3}. The noise becomes much more upsetting if the source of noise is an agent or agency that has shown little concern for the individual who is suffering from the noise's effects and, as a result, nothing has been done to reduce the noise. Noise is not only inconvenient and annoying, but it has also been proven to be a health hazard, many have reported that they suffered with behavioral and emotional consequences, such as difficulty in sleeping, relaxing and feeling annoyed, angry or upset ~\cite{2}, and when intrusive noises continue, the body responds physiologically, and there is a risk of irreversible bodily damage - damage to the circulatory, cardiovascular, and gastrointestinal systems - over time ~\cite{1}.


In order to identify the source and mitigate this problem, there is a need to understand sound event detection ~\cite{6}. Sound event detection is defined as recognition of individual sound events in audio, e.g., “dog barking, engine exhaust noise” requiring estimation of onset and offset for distinct sound as for identification of sound. There are multiple challenges for sound event detection and classifying them into various classes especially when it is to detect in multiple environments or large sets of data, or when there is overlapping of sound events or mixture of sound signals from sensors or identifying the similar sounds compared to the other distinct sound that is harder to classify the source ~\cite{8}. So, it's important to evaluate the data set with actual recordings from urban noise sensors and to identify the sounds by classifying them into classes or labels. In this article we take the large data set which comprises of 3068 labeled 10 sec recordings from the Sounds of New York City (SONYC) acoustic network ~\cite{7} (An acoustic network is a method of positioning equipment using sound waves) . Using this data, we plan to develop a machine learning model that classifies the audio sounds into particular categories based on the attributes or features and also further analyze it to find out the source. We also plan to address the mismatch of the testing data in this data set.

This can be done by applying machine learning algorithm on the data set and then analyzing it for the development of machine learning systems for real world urban noise monitoring. The timeline and work flow (Fig. 3.) for this is depicted below where The model that is devised from the data can be used on urban neighborhoods to better understand noise in that location and help the authorities mitigate this issue.